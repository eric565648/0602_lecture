{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-3 Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (15, 15)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Face Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "\n",
    "img = cv2.imread('images/face.jpg')\n",
    "vis = cv2.imread('images/face.jpg')\n",
    "\n",
    "# Face detector\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "%time faces = faceCascade.detectMultiScale(gray, scaleFactor=2, minNeighbors=5, minSize=(10, 10), flags = 4)\n",
    "# You can find detail descriptions of these functions in the reference below\n",
    "\n",
    "# Visualization\n",
    "dst = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst1 = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(dst1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(dst, cmap = 'brg')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst1, cmap = 'brg')\n",
    "plt.title(\"Found {0} faces!\".format(len(faces))), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's detect faces in group photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/group_1.jpg')\n",
    "vis = cv2.imread('images/group_1.jpg')\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5, minSize=(10, 10), flags = 4)\n",
    "\n",
    "# Visualization\n",
    "dst = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst1 = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(dst1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(dst, cmap = 'brg')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst1, cmap = 'brg')\n",
    "plt.title(\"Found {0} faces!\".format(len(faces))), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "Cascade Classification: https://docs.opencv.org/3.0-beta/modules/objdetect/doc/cascade_classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle (Circle Pattern) Detector\n",
    "\n",
    "See detail in 50-misc-additional-functionality/vehicle_detection/src/vehicle_detection_node.pyvehicle_detection/src/vehicle_detection_node.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/circle.jpg')\n",
    "\n",
    "# Use blob detector to detect the blob pattern in the back of Duckiebots\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "circlepattern_dims = tuple([7, 3]) # Tell the detector what's the pattern looks like\n",
    "params.minArea = 10\n",
    "params.minDistBetweenBlobs = 2\n",
    "simple_blob_detector = cv2.SimpleBlobDetector(params)\n",
    "\n",
    "#(detection, corners) = cv2.findCirclesGrid(img, circlepattern_dims, flags=cv2.CALIB_CB_SYMMETRIC_GRID,blobDetector=simple_blob_detector)\n",
    "%time (detection, corners) = cv2.findCirclesGrid(img, circlepattern_dims, flags=cv2.CALIB_CB_SYMMETRIC_GRID)\n",
    "print (corners)\n",
    "\n",
    "# Visualization\n",
    "dst = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.drawChessboardCorners(dst, circlepattern_dims, corners, detection)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img, cmap = 'brg')\n",
    "plt.title('Origin'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(dst, cmap = 'brg')\n",
    "plt.title('Circle Pattern 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "SimpleBlobDetector: https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html\n",
    "\n",
    "Camera Calibration and 3D Reconstruction: https://docs.opencv.org/3.0-beta/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duckie Detector\n",
    "\n",
    "See detail in 50-misc-additional-functionality/mdoap/src/static_object_detector_node.py\n",
    "\n",
    "You may need to change the high/low color thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONE = [np.array(x, np.uint8) for x in [[0,80,80], [22, 255,255]] ]\n",
    "DUCK = [np.array(x, np.uint8) for x in [[15,100,150], [35, 255, 255]] ]\n",
    "\n",
    "img = cv2.imread('images/duckie_1.jpg')\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "frame_threshed = cv2.inRange(hsv_img, DUCK[0], DUCK[1])\n",
    "ret,thresh = cv2.threshold(frame_threshed,15,255,0)\n",
    "    \n",
    "dst1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(121),plt.imshow(dst1, cmap = 'brg')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(frame_threshed, cmap = 'gray')\n",
    "plt.title('HSV Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to get filtered contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to find the \n",
    "def get_filtered_contours(img, contour_type):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # First do color thresholding\n",
    "    if contour_type == \"CONE\":\n",
    "        frame_threshed = cv2.inRange(hsv_img, CONE[0], CONE[1])\n",
    "        ret,thresh = cv2.threshold(frame_threshed,22,255,0)\n",
    "    elif contour_type == \"DUCK_COLOR\":\n",
    "        frame_threshed = cv2.inRange(hsv_img, DUCK[0], DUCK[1])\n",
    "        ret,thresh = cv2.threshold(frame_threshed,25,255,0)\n",
    "    elif contour_type == \"DUCK_CANNY\":\n",
    "        frame_threshed = cv2.inRange(hsv_img, DUCK[0], DUCK[1])\n",
    "        frame_threshed = cv2.adaptiveThreshold(frame_threshed,255,\\\n",
    "                cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,5,2)\n",
    "        thresh = cv2.Canny(frame_threshed, 100,200)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    filtered_contours = []\n",
    "\n",
    "    # find contour in of the \"Yellow region\"\n",
    "    img, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_area = [ (cv2.contourArea(c), (c) ) for c in contours]\n",
    "    contour_area = sorted(contour_area,reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    height,width = img.shape[:2]\n",
    "    for (area,(cnt)) in contour_area:\n",
    "    # plot box around contour\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        box = (x,y,w,h)\n",
    "        d =  0.5*(x-width/2)**2 + (y-height)**2\n",
    "        if not(h>15 and w >10 and h<200 and w<200 and d < 120000):\n",
    "            # Get rid of contour that is too small or too large\n",
    "            continue\n",
    "        if contour_type == \"DUCK_CANNY\":\n",
    "            continue\n",
    "        if contour_type ==\"DUCK_COLOR\": # extra filtering to remove lines\n",
    "            if not(h>25 and w>25):\n",
    "                continue\n",
    "            if d>90000:\n",
    "                if not(h>35 and w>35):\n",
    "                    continue\n",
    "            if cv2.contourArea(cnt)==0:\n",
    "                continue\n",
    "            val = cv2.arcLength(cnt,True)**2/ cv2.contourArea(cnt)\n",
    "            if val > 35: continue\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            ctr, sides, deg = rect\n",
    "            val  = 0.5*cv2.arcLength(cnt,True) / (w**2+h**2)**0.5\n",
    "            if val < 1.12: continue\n",
    "            #if area > 1000: continue\n",
    "\n",
    "        mask = np.zeros(thresh.shape,np.uint8)\n",
    "        cv2.drawContours(mask,[cnt],0,255,-1)\n",
    "        mean_val = cv2.mean(img,mask = mask)\n",
    "        aspect_ratio = float(w)/h\n",
    "        filtered_contours.append( (cnt, box, d, aspect_ratio, mean_val) )\n",
    "    \n",
    "    return filtered_contours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's detect duckie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/duckie_1.jpg')\n",
    "\n",
    "duck_contours = get_filtered_contours(img, \"DUCK_COLOR\")\n",
    "\n",
    "for (cnt, box, ds, aspect_ratio, mean_color)  in duck_contours:\n",
    "    # plot box around contour\n",
    "    x,y,w,h = box\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, \"DUCKIE\", (x,y-5), font, 0.5, mean_color, 2)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h), mean_color,2)\n",
    "\n",
    "dst1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(121),plt.imshow(dst1, cmap = 'brg')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "Find Countours: https://docs.opencv.org/3.0-beta/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=find%20contours#cv2.findContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
